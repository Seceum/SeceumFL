{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Tutorial of HeteroNN with Pytorch Backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we offer two examples: A standard binary classification task and A simple recommendation task, to show you how to use the Pytorch sequential to build Hetero-NN model structures. Besides these two examples, we have some extra contents below to show you the usage of some Pytorch layers, like LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Pipeline` is distributed along with [fate_client](https://pypi.org/project/fate-client/).\n",
    "\n",
    "```bash\n",
    "pip install fate_client\n",
    "```\n",
    "\n",
    "To use Pipeline, we need to first specify which `FATE Flow Service` to connect to. Once `fate_client` installed, one can find an cmd enterpoint name `pipeline`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: pipeline [OPTIONS] COMMAND [ARGS]...\r\n",
      "\r\n",
      "Options:\r\n",
      "  --help  Show this message and exit.\r\n",
      "\r\n",
      "Commands:\r\n",
      "  config  pipeline config tool\r\n",
      "  init    \b - DESCRIPTION: Pipeline Config Command.\r\n"
     ]
    }
   ],
   "source": [
    "!pipeline --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume we have a `FATE Flow Service` in 127.0.0.1:9380(defaults in standalone), then exec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline configuration succeeded.\r\n"
     ]
    }
   ],
   "source": [
    "!pipeline init --ip 127.0.0.1 --port 9380"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hetero NN Binary Task Example - Pytorch Backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will show you how to build the bottom/interactive/top models sturctures of Hetero-NN model with Pytorch sequential components. Before start a modeling task, data to be used should be uploaded. Please refer to this [guide](https://github.com/FederatedAI/FATE/blob/master/doc/tutorial/pipeline/pipeline_tutorial_upload.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pipeline` package provides components to compose a `FATE pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.backend.pipeline import PipeLine\n",
    "from pipeline.component import Reader, DataTransform, Intersection, HeteroNN, Evaluation\n",
    "from pipeline.interface import Data, Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import torch, fate_torch, and fate_torch_hook. **Do Remember to call fate_torch_hook**, this function is important because it modifies origin torch native functions/classes. This allows FATE-pipeline to parse the definition of PyTorch's sequential, optimizers, loss functions, and initializers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "from torch import optim\n",
    "\n",
    "from pipeline import fate_torch_hook\n",
    "from pipeline import fate_torch as ft\n",
    "\n",
    "from collections import OrderedDict\n",
    "# Call fate_torch_hook, this is important\n",
    "t = fate_torch_hook(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we make a `pipeline` instance:\n",
    "\n",
    "    - initiator: \n",
    "        * role: guest\n",
    "        * party: 9999\n",
    "    - roles:\n",
    "        * guest: 9999\n",
    "        * host: 10000\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "guest_party_id = 9999\n",
    "host_party_id = 10000\n",
    "\n",
    "pipeline = PipeLine() \\\n",
    "        .set_initiator(role='guest', party_id=guest_party_id) \\\n",
    "        .set_roles(guest=guest_party_id, host=host_party_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a `Reader` to load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader_0 = Reader(name=\"reader_0\")\n",
    "# set guest parameter\n",
    "reader_0.get_party_instance(role='guest', party_id=guest_party_id).component_param(\n",
    "    table={\"name\": \"breast_hetero_guest\", \"namespace\": \"experiment\"})\n",
    "# set host parameter\n",
    "reader_0.get_party_instance(role='host', party_id=host_party_id).component_param(\n",
    "    table={\"name\": \"breast_hetero_host\", \"namespace\": \"experiment\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a `DataTransform` component to parse raw data into Data Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform_0 = DataTransform(name=\"data_transform_0\")\n",
    "# set guest parameter\n",
    "data_transform_0.get_party_instance(role='guest', party_id=guest_party_id).component_param(\n",
    "    with_label=True)\n",
    "data_transform_0.get_party_instance(role='host', party_id=[host_party_id]).component_param(\n",
    "    with_label=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a `Intersection` component to perform PSI for hetero-scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersect_0 = Intersection(name=\"intersect_0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can build the structures of the Hetero-NN model locally with PyTorch. In this case, the guest bottom model and host bottom model are sequential that contains 2 layers. The guest top model is a sequential contians 1 layer and sigmoid activation. The Interactive model is a single linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guest bottom model\n",
    "guest_bottom_a = nn.Linear(10, 10, True)\n",
    "guest_bottom_b = nn.Linear(10, 8, True)\n",
    "guest_bottom_seq = t.nn.Sequential(\n",
    "    OrderedDict([\n",
    "        ('layer_0', guest_bottom_a),\n",
    "        ('relu_0', nn.ReLU()),\n",
    "        ('layer_1', guest_bottom_b),\n",
    "        ('relu_1', nn.ReLU())\n",
    "    ])\n",
    ")\n",
    "\n",
    "# host bottom model\n",
    "host_bottom_model = nn.Sequential(\n",
    "    nn.Linear(20, 16, True),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 8, True),\n",
    "    nn.ReLU()\n",
    ")\n",
    "\n",
    "# interactive layer\n",
    "interactive_layer = nn.Linear(8, 4, True)\n",
    "\n",
    "# guest top model\n",
    "guest_top_seq = t.nn.Sequential(\n",
    "    nn.Linear(4, 1, True),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining the model structures, we initialize model parameters(weight & bias) with torch initializers. These initializers are modified, so it can initialize whole sequential. And you can decide to initialize weight or bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init bottom models\n",
    "init.normal_(guest_bottom_seq)\n",
    "init.normal_(host_bottom_model)\n",
    "init.normal_(guest_bottom_seq, init='bias')\n",
    "# init interactive layer\n",
    "init.normal_(interactive_layer, init='weight')\n",
    "init.constant_(interactive_layer, val=0, init='bias')\n",
    "# init top model\n",
    "init.xavier_normal_(guest_top_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define loss function and optimizer needed for the training. **Please notice that after fate torch hook, optimizers can be created without parameters**, this modification is better for pipeline compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "ce_loss_fn = nn.BCELoss()\n",
    "# optimizer, after fate torch hook optimizer can be created without parameters\n",
    "opt = optim.Adam(lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can add each network structure to the Hetero-NN component and compile it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make HeteroNN components and define some parameters\n",
    "hetero_nn_0 = HeteroNN(name=\"hetero_nn_0\", epochs=10, floating_point_precision=None,\n",
    "                       interactive_layer_lr=0.01, batch_size=-1, early_stop=\"diff\")\n",
    "\n",
    "# add sub-component to hetero_nn_0\n",
    "guest_nn_0 = hetero_nn_0.get_party_instance(role='guest', party_id=guest_party_id)\n",
    "guest_nn_0.add_bottom_model(guest_bottom_seq)\n",
    "guest_nn_0.add_top_model(guest_top_seq)\n",
    "guest_nn_0.set_interactve_layer(interactive_layer)\n",
    "\n",
    "host_nn_0 = hetero_nn_0.get_party_instance(role='host', party_id=host_party_id)\n",
    "host_nn_0.add_bottom_model(host_bottom_model)\n",
    "# compile model with torch optimizer\n",
    "hetero_nn_0.compile(opt, loss=ce_loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show the evaluation result, an \"Evaluation\" component is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_0 = Evaluation(name=\"evaluation_0\", eval_type=\"binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then compile our pipeline to make it ready for submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pipeline.backend.pipeline.PipeLine at 0x7f5cdd16dd90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hetero_nn_1 = HeteroNN(name=\"hetero_nn_1\")\n",
    "\n",
    "pipeline.add_component(reader_0)\n",
    "pipeline.add_component(data_transform_0, data=Data(data=reader_0.output.data))\n",
    "pipeline.add_component(intersect_0, data=Data(data=data_transform_0.output.data))\n",
    "pipeline.add_component(hetero_nn_0, data=Data(train_data=intersect_0.output.data))\n",
    "pipeline.add_component(hetero_nn_1, data=Data(test_data=intersect_0.output.data),\n",
    "                       model=Model(model=hetero_nn_0.output.model))\n",
    "pipeline.add_component(evaluation_0, data=Data(data=hetero_nn_0.output.data))\n",
    "pipeline.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, submit(fit) our pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2022-08-25 14:27:05.915\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mJob id is 202208251427054295830\n",
      "\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:05.926\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KJob is still waiting, time elapse: 0:00:00\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:06.937\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KJob is still waiting, time elapse: 0:00:01\u001b[0m\n",
      "\u001b[0mm2022-08-25 14:27:07.953\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1m\n",
      "\u001b[32m2022-08-25 14:27:07.954\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:02\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:08.970\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:03\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:09.988\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:04\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:11.008\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:05\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:12.021\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:06\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:13.038\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:07\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:14.052\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component reader_0, time elapse: 0:00:08\u001b[0m\n",
      "\u001b[0mm2022-08-25 14:27:16.090\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1m\n",
      "\u001b[32m2022-08-25 14:27:16.092\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component data_transform_0, time elapse: 0:00:10\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:17.107\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component data_transform_0, time elapse: 0:00:11\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:18.125\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component data_transform_0, time elapse: 0:00:12\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:19.141\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component data_transform_0, time elapse: 0:00:13\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:20.157\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component data_transform_0, time elapse: 0:00:14\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:21.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component data_transform_0, time elapse: 0:00:15\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:22.195\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component data_transform_0, time elapse: 0:00:16\u001b[0m\n",
      "\u001b[0mm2022-08-25 14:27:23.216\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1m\n",
      "\u001b[32m2022-08-25 14:27:23.217\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component intersect_0, time elapse: 0:00:17\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:24.243\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component intersect_0, time elapse: 0:00:18\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:25.261\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component intersect_0, time elapse: 0:00:19\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:26.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component intersect_0, time elapse: 0:00:20\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:27.292\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component intersect_0, time elapse: 0:00:21\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:28.306\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component intersect_0, time elapse: 0:00:22\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:29.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component intersect_0, time elapse: 0:00:23\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:30.336\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component intersect_0, time elapse: 0:00:24\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:31.350\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component intersect_0, time elapse: 0:00:25\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:32.368\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component intersect_0, time elapse: 0:00:26\u001b[0m\n",
      "\u001b[0mm2022-08-25 14:27:33.385\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1m\n",
      "\u001b[32m2022-08-25 14:27:33.386\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:00:27\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:34.404\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:00:28\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:35.426\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:00:29\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:36.442\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:00:30\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:37.458\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:00:31\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:38.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:00:32\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:39.489\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:00:33\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:40.506\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:00:34\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:41.524\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:00:35\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2022-08-25 14:27:42.545\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:00:36\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:43.561\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:00:37\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:44.580\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:00:38\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:45.594\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:00:39\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:46.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:00:40\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:47.636\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:00:41\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:48.651\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:00:42\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:49.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:00:43\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:50.680\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:00:44\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:51.696\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:00:45\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:52.718\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:00:46\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:53.732\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:00:47\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:54.759\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:00:48\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:55.777\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:00:49\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:56.796\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:00:50\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:57.813\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:00:51\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:58.827\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:00:52\u001b[0m\n",
      "\u001b[32m2022-08-25 14:27:59.844\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:00:53\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:00.861\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:00:54\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:01.880\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:00:55\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:02.898\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:00:56\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:03.913\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:00:57\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:04.928\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:00:59\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:05.943\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:00\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:06.957\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:01\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:07.973\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:02\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:08.990\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:03\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:10.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:04\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:11.040\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:05\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:12.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:06\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:13.077\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:07\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:14.091\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:08\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:15.109\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:09\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:16.128\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:10\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:17.144\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:11\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:18.177\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:12\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:19.195\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:13\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:20.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:14\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:21.227\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:15\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2022-08-25 14:28:22.242\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:16\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:23.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:17\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:24.272\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:18\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:25.287\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:19\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:26.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:20\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:27.319\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:21\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:28.336\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:22\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:29.351\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:23\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:30.365\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:24\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:31.383\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:25\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:32.398\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:26\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:33.416\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:27\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:34.432\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:28\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:35.452\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:29\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:36.466\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:30\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:37.481\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:31\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:38.498\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:32\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:39.515\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:33\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:40.528\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:34\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:41.541\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:35\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:42.557\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:36\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:43.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:37\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:44.586\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:38\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:45.600\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:39\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:46.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:40\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:47.628\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:41\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:48.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:42\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:49.665\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:43\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:50.680\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:44\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:51.694\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:45\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:52.710\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:46\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:53.724\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:47\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:54.737\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:48\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:55.751\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:49\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:56.764\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:50\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:57.776\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:51\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:58.788\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:52\u001b[0m\n",
      "\u001b[32m2022-08-25 14:28:59.802\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:53\u001b[0m\n",
      "\u001b[32m2022-08-25 14:29:00.821\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:54\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2022-08-25 14:29:01.836\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:55\u001b[0m\n",
      "\u001b[32m2022-08-25 14:29:02.849\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_0, time elapse: 0:01:56\u001b[0m\n",
      "\u001b[0mm2022-08-25 14:29:03.877\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1m\n",
      "\u001b[32m2022-08-25 14:29:03.881\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_1, time elapse: 0:01:57\u001b[0m\n",
      "\u001b[32m2022-08-25 14:29:04.896\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_1, time elapse: 0:01:58\u001b[0m\n",
      "\u001b[32m2022-08-25 14:29:05.909\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_1, time elapse: 0:01:59\u001b[0m\n",
      "\u001b[32m2022-08-25 14:29:06.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_1, time elapse: 0:02:01\u001b[0m\n",
      "\u001b[32m2022-08-25 14:29:07.938\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_1, time elapse: 0:02:02\u001b[0m\n",
      "\u001b[32m2022-08-25 14:29:08.951\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_1, time elapse: 0:02:03\u001b[0m\n",
      "\u001b[32m2022-08-25 14:29:09.967\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_1, time elapse: 0:02:04\u001b[0m\n",
      "\u001b[32m2022-08-25 14:29:10.981\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_1, time elapse: 0:02:05\u001b[0m\n",
      "\u001b[32m2022-08-25 14:29:11.995\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_1, time elapse: 0:02:06\u001b[0m\n",
      "\u001b[32m2022-08-25 14:29:13.009\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_1, time elapse: 0:02:07\u001b[0m\n",
      "\u001b[32m2022-08-25 14:29:14.022\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_1, time elapse: 0:02:08\u001b[0m\n",
      "\u001b[32m2022-08-25 14:29:15.036\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_1, time elapse: 0:02:09\u001b[0m\n",
      "\u001b[32m2022-08-25 14:29:16.051\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_1, time elapse: 0:02:10\u001b[0m\n",
      "\u001b[32m2022-08-25 14:29:17.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_1, time elapse: 0:02:11\u001b[0m\n",
      "\u001b[32m2022-08-25 14:29:18.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component hetero_nn_1, time elapse: 0:02:12\u001b[0m\n",
      "\u001b[0mm2022-08-25 14:29:19.095\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1m\n",
      "\u001b[32m2022-08-25 14:29:19.096\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component evaluation_0, time elapse: 0:02:13\u001b[0m\n",
      "\u001b[32m2022-08-25 14:29:20.115\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component evaluation_0, time elapse: 0:02:14\u001b[0m\n",
      "\u001b[32m2022-08-25 14:29:21.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component evaluation_0, time elapse: 0:02:15\u001b[0m\n",
      "\u001b[32m2022-08-25 14:29:22.150\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component evaluation_0, time elapse: 0:02:16\u001b[0m\n",
      "\u001b[32m2022-08-25 14:29:23.166\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component evaluation_0, time elapse: 0:02:17\u001b[0m\n",
      "\u001b[32m2022-08-25 14:29:24.181\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component evaluation_0, time elapse: 0:02:18\u001b[0m\n",
      "\u001b[32m2022-08-25 14:29:25.195\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[80D\u001b[1A\u001b[KRunning component evaluation_0, time elapse: 0:02:19\u001b[0m\n",
      "\u001b[32m2022-08-25 14:29:26.206\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m89\u001b[0m - \u001b[1mJob is success!!! Job id is 202208251427054295830\u001b[0m\n",
      "\u001b[32m2022-08-25 14:29:26.208\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpipeline.utils.invoker.job_submitter\u001b[0m:\u001b[36mmonitor_job_status\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mTotal time: 0:02:20\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pipeline.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hetero NN RecommendationTask Example - Pytorch Backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Example we show you how to use pytorch backend and fate-torch operations to build a simple recommendation task. Firstly we introduce the dataset. We use the Movielens-100K dataset, guest side holds the records of user-item interactions, while host side has some categoriacl movie meta data. Thus, this task requires sparse input data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to define pipeline components that read and align data, like the first example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "from collections import OrderedDict\n",
    "from pipeline.backend.pipeline import PipeLine\n",
    "from pipeline.component import DataTransform\n",
    "from pipeline.component import HeteroNN\n",
    "from pipeline.component import Intersection\n",
    "from pipeline.component import Reader\n",
    "from pipeline.component import Evaluation\n",
    "from pipeline.interface import Data\n",
    "from pipeline.utils.tools import load_job_config\n",
    "from pipeline.interface import Model\n",
    "\n",
    "from pipeline import fate_torch_hook\n",
    "import torch as t\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "from torch import optim\n",
    "from pipeline import fate_torch as ft\n",
    "\n",
    "# this is important, modify torch modules so that Sequential model be parsed by pipeline\n",
    "fate_torch_hook(t)\n",
    "\n",
    "guest_train_data = {\"name\": \"ml_hetero_guest\", \"namespace\": f\"experiment{namespace}\"}\n",
    "host_train_data = {\"name\": \"ml_hetero_host\", \"namespace\": f\"experiment{namespace}\"}\n",
    "\n",
    "pipeline = PipeLine().set_initiator(role='guest', party_id=guest).set_roles(guest=guest, host=host)\n",
    "\n",
    "reader_0 = Reader(name=\"reader_0\")\n",
    "reader_0.get_party_instance(role='guest', party_id=guest).component_param(table=guest_train_data)\n",
    "reader_0.get_party_instance(role='host', party_id=host).component_param(table=host_train_data)\n",
    "\n",
    "data_transform_0 = DataTransform(name=\"data_transform_0\")\n",
    "data_transform_0.get_party_instance(role='guest', party_id=guest).component_param(with_label=True,\n",
    "                                                                                  label_name='label')\n",
    "data_transform_0.get_party_instance(role='host', party_id=host).component_param(with_label=False)\n",
    "\n",
    "intersection_0 = Intersection(name=\"intersection_0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key step is building the structures of guest/host NN components. Because for now Hetero-NN only supports parsing PyTorch sequential, we need to build Embedding layers in 1 sequential.\n",
    "\n",
    "The Pytorch embedding layers take long type as input, so the first layer of sequential is to use an operation layer Astype in fate-torch to cast input to Long type. We have 610 users and 9742 items in this interaction records, and they will be fed into the embedding layer in pairs,  like ([0, 612]) for example. So we use an Embedding layer containing 610 + 9742 embeddings, and item indices will be offset by 610 in the dataset.  The third layer of the sequential is a fate-torch operation that reshapes the output of embedding layers, this operation concatenates user and item embeddings. Then, finally embedding will be fed into a linear layer following a ReLu activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.5611, 0.0000, 1.5532, 1.7774, 0.0394, 0.0000, 0.0000, 0.4997]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# define embedding model\n",
    "u_embd_count = 610  # idx 0 - 609 user embed\n",
    "i_embd_count = 9742  # idx 611 - 10351 item embed\n",
    "\n",
    "# guest model handle user-movie interaction pairs, user and movie share same Embedding layers\n",
    "guest_model = t.nn.Sequential(\n",
    "    ft.operation.Astype('int64'),  # cast to long\n",
    "    t.nn.Embedding(u_embd_count + i_embd_count + 1, embedding_dim=8),\n",
    "    ft.operation.Reshape((-1, 16)),  # fate_torch operation that concatenates u-i embeddings\n",
    "    t.nn.Linear(16, 8),\n",
    "    t.nn.ReLU()\n",
    ")\n",
    "\n",
    "# test guest_bottom model\n",
    "test_u_i = t.Tensor([[0, 639]])\n",
    "test_out = guest_model(test_u_i)\n",
    "print(test_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The guest top model is a sequential contians 1 layer and sigmoid activation, like previous example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guest top model outputs score between 0-1\n",
    "guest_top_model = t.nn.Sequential(\n",
    "    t.nn.ReLU(),\n",
    "    t.nn.Linear(4, 1),\n",
    "    t.nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Host model has movie categorical features, transform them into dense feature using Embeddings. Host side has 21 movie genres, and use 0 as the padding index. We sum all embedding to generate a dense feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.4943, 6.1790, 3.8077, 5.0657, 1.8655, 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "host_model = t.nn.Sequential(\n",
    "    ft.operation.Astype('int64'),  # cast to long\n",
    "    t.nn.Embedding(21, embedding_dim=16, padding_idx=0),  # use 0 as padding index\n",
    "    ft.operation.Sum(dim=1),  # operation that sum all categorical embeddings\n",
    "    t.nn.Linear(16, 8),\n",
    "    t.nn.ReLU()\n",
    ")\n",
    "\n",
    "# test categorical fatures\n",
    "feat = t.Tensor([[1, 12, 13, 14, 15, 0, 0, 0, 0, 0]])\n",
    "print(host_model(feat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interactive layer takes the addition of guest&host model Embeddings as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_layer = t.nn.Linear(8, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then finally we can add these models into Hetero-NN, and start training a recommendation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "ce_loss_fn = nn.BCELoss()\n",
    "\n",
    "# optimizer, after fate torch hook optimizer can be created without parameters\n",
    "opt: ft.optim.Adam = optim.Adam(lr=0.01)\n",
    "\n",
    "hetero_nn_0 = HeteroNN(name=\"hetero_nn_0\", epochs=1, floating_point_precision=None,\n",
    "                       interactive_layer_lr=0.01, batch_size=4096, early_stop=\"diff\")\n",
    "\n",
    "guest_nn_0 = hetero_nn_0.get_party_instance(role='guest', party_id=guest)\n",
    "guest_nn_0.add_bottom_model(guest_model)\n",
    "guest_nn_0.add_top_model(guest_top_model)\n",
    "guest_nn_0.set_interactve_layer(interactive_layer)\n",
    "host_nn_0 = hetero_nn_0.get_party_instance(role='host', party_id=host)\n",
    "\n",
    "host_nn_0.add_bottom_model(host_model)\n",
    "# compile model with torch optimizer\n",
    "hetero_nn_0.compile(opt, loss=ce_loss_fn)\n",
    "\n",
    "hetero_nn_1 = HeteroNN(name=\"hetero_nn_1\")\n",
    "evaluation_0 = Evaluation(name=\"evaluation_0\")\n",
    "\n",
    "pipeline.add_component(reader_0)\n",
    "pipeline.add_component(data_transform_0, data=Data(data=reader_0.output.data))\n",
    "pipeline.add_component(intersection_0, data=Data(data=data_transform_0.output.data))\n",
    "pipeline.add_component(hetero_nn_0, data=Data(train_data=intersection_0.output.data))\n",
    "pipeline.add_component(hetero_nn_1, data=Data(test_data=intersection_0.output.data),\n",
    "                       model=Model(model=hetero_nn_0.output.model))\n",
    "pipeline.add_component(evaluation_0, data=Data(data=hetero_nn_0.output.data))\n",
    "pipeline.compile()\n",
    "pipeline.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some examples of Pytorch and Fate-Torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the convenience of using pytorch backend, we offer some operation layers in fate-torch so that users will be able to use some complex layer, like LSTM. Here's some examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'torch' from '/data/projects/fate/common/python/venv/lib/python3.8/site-packages/torch/__init__.py'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch as t\n",
    "from pipeline import fate_torch as ft\n",
    "from pipeline import fate_torch_hook\n",
    "\n",
    "fate_torch_hook(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we create a fake word sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_word_seq = t.randint(1, 32, (64, 5)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example of using LSTM in sequentials, we firstly cast input type to int64(long), feed sequence into Embedding layer and LSTM layer,\n",
    "then sum all word embeddings in lstm output sequence together to produce a dense output. We use ft.operation.Index(0) to pick outputs from tuple (outputs, (h_n, c_n))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.7123, 4.7123, 4.7180,  ..., 4.7159, 4.7142, 4.7190],\n",
      "        [4.6503, 4.6536, 4.6853,  ..., 4.6505, 4.6576, 4.7024],\n",
      "        [4.6771, 4.6778, 4.7010,  ..., 4.6801, 4.6823, 4.7104],\n",
      "        ...,\n",
      "        [4.6044, 4.5972, 4.6423,  ..., 4.5680, 4.5999, 4.6759],\n",
      "        [4.7167, 4.7167, 4.7194,  ..., 4.7186, 4.7177, 4.7197],\n",
      "        [4.5361, 4.5358, 4.5816,  ..., 4.4659, 4.5261, 4.6402]],\n",
      "       grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "seq_with_lstm = t.nn.Sequential(\n",
    "    ft.operation.Astype('int64'),\n",
    "    t.nn.Embedding(32, embedding_dim=16, padding_idx=0),\n",
    "    t.nn.LSTM(input_size=16, hidden_size=16, num_layers=3, batch_first=True),\n",
    "    ft.operation.Index(0),\n",
    "    ft.operation.Sum(dim=1)\n",
    ")\n",
    "\n",
    "print(seq_with_lstm(fake_word_seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we select the last embedding of output sequence.The origin output shape is (64, 20, 16), the sequence length is 20, we select the last embedding using Select."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 16])\n"
     ]
    }
   ],
   "source": [
    "lstm_module = t.nn.LSTM(input_size=16, hidden_size=16, num_layers=3, batch_first=True)\n",
    "embd = t.nn.Embedding(32, embedding_dim=16, padding_idx=0)\n",
    "t.nn.init.normal_(embd)\n",
    "t.nn.init.xavier_normal_(lstm_module)\n",
    "\n",
    "seq_with_lstm = t.nn.Sequential(\n",
    "    ft.operation.Astype('int64'),\n",
    "    embd, \n",
    "    lstm_module,\n",
    "    ft.operation.Index(0),\n",
    "    ft.operation.Select(dim=1, idx=-1), # dim 1, index last\n",
    ")\n",
    "\n",
    "out = seq_with_lstm(fake_word_seq)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layers offered in pytorch nn modules are supported . Use them to build hetero-nn sturectures in Sequential."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more demo on using pipeline to submit jobs, please refer to [pipeline demos](https://github.com/FederatedAI/FATE/tree/master/examples/pipeline/demo)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad4309918fa4cd1705b305e369b2f64d901b1851e9144aef7b9b07ea3efcb1bb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
